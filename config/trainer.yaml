defaults:
  - _self_
  - tokenizer: default
  - world_model: default
  - actor_critic: default
  - env: default
  - datasets: default

wandb:
  mode: disabled # 控制 W&B 的运行模式 含义：disabled 表示不连接 W&B 服务器 使用效果：代码可以运行但不会向 W&B 服务器发送数据 使用场景：本地开发或无需记录时
  project: iris # 作用：设置项目名称 含义：指定实验记录保存的项目 使用效果：实验数据在 W&B 界面中归类到名为 'iris' 的项目 使用场景：组织多个相关实验
  entity: null # 作用：设置团队或用户名称 含义：指定项目所属的组织或个人 使用效果：实验归属于特定团队或用户 使用场景：团队协作开发时
  name: null # 作用：为当前运行指定一个名称 含义：自定义运行实例的显示名称 使用效果：在 W&B 界面中以此名称显示实验 使用场景：需要直观命名实验时
  group: null # 作用：实验分组 含义：将相关实验归为一组 使用效果：可在 W&B 界面中按组筛选和分析 使用场景：比较相似实验变体时
  tags: null # 作用：添加标签 含义：为实验添加关键词标签 使用效果：便于在 W&B 界面中过滤和搜索 使用场景：需要快速筛选特定实验时
  notes: null # 作用：添加实验备注 含义：记录实验的额外说明信息 使用效果：在 W&B 界面中显示详细说明 使用场景：需要记录实验特殊情况或假设时

initialization:
  path_to_checkpoint: null
  load_tokenizer: False
  load_world_model: False
  load_actor_critic: False

common:
  epochs: 600
  device: cuda:0
  do_checkpoint: True
  seed: 0
  sequence_length: ${world_model.max_blocks}
  resume: False # set by resume.sh script only.

collection:
  train:
    num_envs: 1
    stop_after_epochs: 500
    num_episodes_to_save: 10
    config:
      epsilon: 0.01
      should_sample: True
      temperature: 1.0
      num_steps: 200
      burn_in: ${training.actor_critic.burn_in}
  test:
    num_envs: 8
    num_episodes_to_save: ${collection.train.num_episodes_to_save}
    config:
      epsilon: 0.0
      should_sample: True
      temperature: 0.5
      num_episodes: 16
      burn_in: ${training.actor_critic.burn_in}

training:
  should: True
  learning_rate: 0.0001
  tokenizer:
    batch_num_samples: 256
    grad_acc_steps: 1
    max_grad_norm: 10.0
    start_after_epochs: 5
    steps_per_epoch: 200
  world_model:
    batch_num_samples: 64
    grad_acc_steps: 1
    max_grad_norm: 10.0
    weight_decay: 0.01
    start_after_epochs: 25
    steps_per_epoch: 200
  actor_critic:
    batch_num_samples: 64
    grad_acc_steps: 1
    max_grad_norm: 10.0
    start_after_epochs: 50
    steps_per_epoch: 200
    imagine_horizon: ${common.sequence_length}
    burn_in: 20
    gamma: 0.995
    lambda_: 0.95
    entropy_weight: 0.001

evaluation:
  should: True
  every: 5
  tokenizer:
    batch_num_samples: ${training.tokenizer.batch_num_samples}
    start_after_epochs: ${training.tokenizer.start_after_epochs}
    save_reconstructions: True
  world_model:
    batch_num_samples: ${training.world_model.batch_num_samples}
    start_after_epochs: ${training.world_model.start_after_epochs}
  actor_critic:
    num_episodes_to_save: ${training.actor_critic.batch_num_samples}
    horizon: ${training.actor_critic.imagine_horizon}
    start_after_epochs: ${training.actor_critic.start_after_epochs}
